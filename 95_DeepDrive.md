
# 논문

- [Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art](https://arxiv.org/abs/1704.05519)

- [Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car](https://arxiv.org/abs/1704.07911)

- [A New Performance Measure and Evaluation Benchmark for Road Detection Algorithms](http://www.cvlibs.net/publications/Fritsch2013ITSC.pdf)


![](https://cdn-images-1.medium.com/max/800/1*HTyatXEYA62kjN_kNxYW7g.png)

[2017: The year for autonomous vehicles](https://machinelearnings.co/2017-the-year-for-autonomous-vehicles-8359fec2d2db#.bh2nr1v38)

# 0. 개요

## Self-Driving Engineer
* [How to Become a Self-Driving Car Engineeer Talk](https://medium.com/self-driving-cars/how-to-become-a-self-driving-car-engineeer-talk-923dfa5e6665#.ig03r4tmq) : 추천, ppt,Jupyter코드 포함
* [But, Self-Driving Car Engineers don’t need to know C/C++, right?](https://medium.com/@mimoralea/but-self-driving-car-engineers-dont-need-to-know-c-c-right-3230725a7542#.1pk5qsb90) : 필요 지식 및 기술(개인 의견)
* [Self Driving Car Engineer Deep Dive](https://medium.com/@paysa/self-driving-car-engineer-deep-dive-89b814f3ff04#.pygljklaq)
* [Who’s Hiring Autonomous Vehicle Engineers](https://medium.com/self-driving-cars/whos-hiring-autonomous-vehicle-engineers-1ccf42185e08#.zd2odb5gs)
- [Five Skills Self-Driving Companies Need](https://hackernoon.com/five-skills-self-driving-companies-need-8546d2aba7c1#.bt1p1a7jq)
- <Del>[5 Things That Give Self-Driving Cars Headaches](https://getpocket.com/a/read/1625729922): 예측 불가 인간, 날씨, 우회길, 웅덩이 </Del>

## Youtube
- [16 Questions About Self-Driving Cars](https://vimeo.com/198256576)[[Q List]](https://medium.com/self-driving-cars/frank-chens-16-questions-about-self-driving-car-3c663987965b#.85q8lxbdy)
- [Autonomous Vehicles Overview](https://www.youtube.com/watch?v=CruCp6vqPQs&feature=youtu.be) : Wiley Jones,2016. 8. 28, 56분, Robotics, actuation, sensors, SLAM, computational platforms

## 논문
* [논문: End to End Learning for Self-Driving](http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf) : NVIDIA 2016 Paper
* [논문: End to End Learning for Self-Driving Cars](https://arxiv.org/abs/1604.07316) : 카메라 3대와 운전자의 핸들 조작+알파로 학습한다음 카메라 하나만 입력으로 사용하고 운전대를 어떻게 움직이는지를 예측하여 자동운전,  [[YOUTUBE]](https://drive.google.com/file/d/0B9raQzOpizn1TkRIa241ZnBEcjQ/view)



# Affordable Self-Driving Cars
- 토론토 대학교 [Raquel Urtasun 교수](http://www.cs.toronto.edu/~urtasun/) 연구팀

- [ppt: Towards Affordable Self-Driving Cars](http://www.nasonline.org/programs/sackler-forum/frontiers-of-machine-learning/urtasun-ppt.pdf)

### Youtube
- [Raquel Urtasun - Towards Affordable Self-Driving Cars - The Frontiers of Machine Learning](https://www.youtube.com/watch?v=sW4M7-xcseI)
- [Raquel Urtasun - Q&A - The Frontiers of Machine Learning](https://www.youtube.com/watch?v=-p4YgPgPkXM)

### Paper
- [TorontoCity: Seeing the World with a Million Eyes](https://arxiv.org/pdf/1612.00423.pdf): 2016


# Nexar
Nexar is a community-based AI dash cam app for iPhone and Android : [홈페이지](https://www.getnexar.com/), [Challenge](https://www.getnexar.com/challenges/)
- You can compete to win prizes (1st place $5,000, 2nd place $2,000, 3rd place iPhone 7)

## Challenge #1 : USING DEEP LEARNING FOR TRAFFIC LIGHT RECOGNITION
[챌리지 개요/요구사항](https://challenge.getnexar.com/challenge-1)
- [Recognizing Traffic Lights With Deep Learning](https://medium.freecodecamp.com/recognizing-traffic-lights-with-deep-learning-23dae23287cc#.l2iu0aqag) : David Brailovsky
- [The world through the eyes of a self-driving car](https://medium.freecodecamp.com/what-is-my-convnet-looking-at-7b0533e4d20e#.wnom5expq) : David Brailovsky

- [How I learned deep learning in 10 weeks, then won $5,000 by recognizing traffic lights](https://medium.freecodecamp.com/how-i-learned-deep-learning-in-10-weeks-then-won-5-000-by-recognizing-traffic-lights-f3e7b1b37ea)

## Challenge #2 : Coming Soon

# commai
- [홈페이지]() [[GitHub]](https://github.com/commaai/research)
- [논문](http://arxiv.org/abs/1608.01230) : Learning a Driving Simulator


# OSSDC

- [Open Source Self Driving Car Initiative](http://ossdc.org): [GitHUb](https://github.com/OSSDC), OSSDC-VisionBasedACC, OSSDC-LKAS, OSSDC-SmartCamera

# AutoX
- 센서 없이 카메라 만으로 자율주행차 구현을 목적으로 함

- [홈페이지](http://autox.ai/): 인트로 동영상외 자료 없음

- [CEO Professor X](http://www.jianxiongxiao.com/?m=1): CEO 프로필

- [AutoX - Self Driving Car startup that makes sense](https://medium.com/@mslavescu/autox-self-driving-car-startup-that-makes-sense-301b3a955979): Meduim 소개글

- [신문 소개글](http://www.businessinsider.com/autox-ceo-jianxiong-xiao-interview-2017-3)

# SegNet
- [Homepage](http://mi.eng.cam.ac.uk/projects/segnet/): 캠프리지
- [논문](https://arxiv.org/pdf/1511.00561.pdf)

# Article
- [Self-driving cars in the browser](http://janhuenermann.com/projects/learning-to-drive)
- [Towards a real-time vehicle detection: SSD multibox approach](https://medium.com/@vivek.yadav/towards-a-real-time-vehicle-detection-ssd-multibox-approach-2519af2751c#.cldxjz489) : Vivek Yadav

- [SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving](https://github.com/BichenWuUCB/squeezeDet): GitHub

# Implementation

- [Source Code for “Self Driving Car Learns Online and On-board on Raspberry Pi 3”](https://ogma.ai/2017/07/source-code-for-self-driving-car-learns-online-and-on-board-on-raspberry-pi-3/)

# Open Data
* [옥스포드 Robot Car Dataset](http://robotcar-dataset.robots.ox.ac.uk/index.html)
* [Comma.ai driving dataset](https://github.com/commaai/research) : 자율 주행, 7.5 hours of camera images, steering angles, and other vehicle data.
* [Traffic Sign](http://www.vision.ee.ethz.ch/~timofter/traffic_signs/) : 신호등 데이터셋
* [BelgiumTS Dataset](http://btsd.ethz.ch/shareddata/index.html) : 도로 안내판 데이터셋
* [Udacity Driving Dataset](https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5#.1aq6pztwj) : Mountain View, 223G(10시간)
- [INI](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset) : 독일 신호등 데이터셋
- [Udacity_Annotated Driving Dataset](https://github.com/udacity/self-driving-car/tree/master/annotations) : 도로상 차량, 트럭, 보행자 4.5GB
- [KITTI](http://www.cvlibs.net/datasets/kitti/): 동영상??
- [GTI](http://www.gti.ssr.upm.es/data/Vehicle_database.html): 차량 이미지 데이터셋
- [CMU Visual Localization Data Set](http://3dvis.ri.cmu.edu/data-sets/localization/): Dataset collected using the Navlab 11 equipped with IMU, GPS, Lidars and cameras.
- [NYU RGB-D Dataset](http://cs.nyu.edu/~silberman/datasets/): Indoor dataset captured with a Microsoft Kinect that provides semantic labels.
- [TUM RGB-D Dataset](http://cvpr.in.tum.de/data/datasets/rgbd-dataset): Indoor dataset captured with Microsoft Kinect and high-accuracy motion capturing.
- [New College Dataset](http://www.robots.ox.ac.uk/NewCollegeData/): 30 GB of data for 6 D.O.F. navigation and mapping (metric or topological) using vision and/or laser.
- [The Rawseeds Project](http://www.rawseeds.org/): Indoor and outdoor datasets with GPS, odometry, stereo, omnicam and laser measurements for visual, laser-based, omnidirectional, sonar and multi-sensor SLAM evaluation.
- [Victoria Park Sequence](http://www-personal.acfr.usyd.edu.au/nebot/victoria_park.htm): Widely used sequence for evaluating laser-based SLAM. Trees serve as landmarks, detection code is included.
- [Malaga Dataset 2009](http://www.mrpt.org/Paper:Malaga_Dataset_2009) and [Malaga Dataset 2013](http://www.mrpt.org/MalagaUrbanDataset): Dataset with GPS, Cameras and 3D laser information, recorded in the city of Malaga, Spain.
- [Ford Campus Vision and Lidar Dataset](http://robots.engin.umich.edu/SoftwareData/Ford): Dataset collected by a Ford F-250 pickup, equipped with IMU, Velodyne and Ladybug.

- [Build Your Own Real Time Traffic Data Feed]http://www.chioka.in/build-your-own-real-time-traffic-data-feed/): 교통카메라를 이용항 차량 이미지 획득 방법에 대하여

- [US 차량 궤적](https://www.fhwa.dot.gov/publications/research/operations/its/06135/index.cfm): NGSIM (Next Generation SIMulation이라 하여 미국 고속도로에 대해 비디오 분석 및 수작업을 통해 추적한 차량의 주행 궤적자료를 포함

# 장비/센서
- [Lida](https://www.blackmoreinc.com/) : [간략 설명](https://medium.com/self-driving-cars/startup-watch-blackmore-1c0f43e24467#.1lfeyxf5f)
- [Mini Autonomous Vehicle](https://medium.com/self-driving-cars/miniature-autonomous-vehicle-dc48d0740afc#.aa4w6l1bs)

- [Startup Watch: Luminar](https://medium.com/self-driving-cars/startup-watch-luminar-39b4e5e89238): Lidar 센서

# Lab
- [버클리대 DeepDrive](http://bdd.berkeley.edu) : 선진 연구 분야 살펴 보기 좋음


# Startups
- [NAUTO](https://medium.com/self-driving-cars/startup-watch-nauto-1fc88c00a809#.51ybxti2k)
- [Zoox]](https://medium.com/self-driving-cars/startup-watch-zoox-b99b64a1db30#.nce3tldm7)

## V2X

- [Autotalks](http://www.auto-talks.com/): automotive-grade communication chips

- [Cohoda Wireless](http://www.cohdawireless.com/): automotive-grade communication chips

- [Kymeta](http://www.kymetacorp.com/): automotive satellite communications

- [RoboCV](http://robocv.com/): collision avoidance with vehicle-to-vehicle communication

- [Savari](http://savari.net/): vehicle-to-anything communication infrastructure

- [Veniam](https://veniam.com/): automotive mesh WiFi
